# app.py
# Streamlit + LangChain simple LLM web app
# Python 3.11
import os
import streamlit as st

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

# ------------------------------
# App metadata
# ------------------------------
APP_TITLE = "LLM Expert Switcher (A/B)"
APP_DESC = """
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨ã€ŒA/Bã€å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠã«åŸºã¥ã„ã¦ã€LLM ã«è³ªå•ã§ãã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¢ã§ã™ã€‚  
å·¦ä¸Šã® *A/B ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³* ã§å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ **é€ä¿¡** ã‚’æŠ¼ã™ã¨å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

- **A**: çµŒå–¶ãƒ»äº‹æ¥­æˆ¦ç•¥ã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”  
- **B**: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»æ©Ÿæ¢°å­¦ç¿’ã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”

â€» æœ¬ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œã«ã¯ OpenAI API ã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚Streamlit Community Cloud ã§ã¯ `secrets` ã« `OPENAI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚
"""

# ------------------------------
# Expert system prompts
# ------------------------------
EXPERT_SYSTEM_PROMPTS = {
    "A": (
        "ã‚ãªãŸã¯ä¸€æµã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª²é¡Œã«å¯¾ã—ã€ç›®çš„â†’æ´å¯Ÿâ†’æ–½ç­–â†’ãƒªã‚¹ã‚¯â†’æ¬¡ã®ä¸€æ‰‹ã®é †ã§ã€"
        "ç°¡æ½”ã‹ã¤å®Ÿå‹™çš„ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯åˆå‡ºã§çŸ­ãå®šç¾©ã—ã€"
        "ç®‡æ¡æ›¸ãã‚’åŠ¹æœçš„ã«ä½¿ã„ã€ç„¡æ ¹æ‹ ãªæ–­å®šã‚’é¿ã‘ã¾ã™ã€‚"
    ),
    "B": (
        "ã‚ãªãŸã¯ä¸€æµã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª²é¡Œã«å¯¾ã—ã€å•é¡Œå®šç¾©â†’ãƒ‡ãƒ¼ã‚¿å‰æâ†’æ‰‹æ³•å€™è£œâ†’è©•ä¾¡æŒ‡æ¨™â†’å®Ÿè£…ã®ç•™æ„ç‚¹â†’ä»£æ›¿æ¡ˆã®é †ã§èª¬æ˜ã—ã¾ã™ã€‚"
        "å¼ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã¯å¿…è¦æœ€å°é™ã¨ã—ã€åˆå­¦è€…ã«ã‚‚ä¼ã‚ã‚‹ã‚ˆã†æ¯”å–©ã‚’ç¹”ã‚Šäº¤ãœã¾ã™ã€‚"
    ),
}

# ------------------------------
# Core LLM function (Required by spec)
# ------------------------------
def ask_llm(user_text: str, expert_choice: str) -> str:
    """
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠå€¤ï¼ˆA/Bï¼‰ã‚’å—ã‘å–ã‚Šã€
    LangChain ã‚’ç”¨ã„ã¦ LLM ã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    if not user_text:
        return "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

    # å®‰å…¨ãªé¸æŠå€¤æ­£è¦åŒ–ï¼ˆA/B ã®ã¿ã‚’è¨±å®¹ï¼‰
    choice = expert_choice.strip().upper()
    if choice not in EXPERT_SYSTEM_PROMPTS:
        choice = "A"

    system_msg = EXPERT_SYSTEM_PROMPTS[choice]

    # LangChain prompt
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_msg),
            (
                "human",
                "æ¬¡ã®å†…å®¹ã«å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
                "ã€è³ªå•ã€‘{question}\n"
                "åˆ¶ç´„: 300ã€œ600æ–‡å­—ã§ã€æ ¹æ‹ ã¨æ³¨æ„ç‚¹ã‚’1ã¤ãšã¤å«ã‚ã‚‹ã€‚",
            ),
        ]
    )

    # ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ Streamlit secrets ã‹ã‚‰å–å¾—ï¼‰
    # secrets ãŒå„ªå…ˆã€ãªã‘ã‚Œã°ç’°å¢ƒå¤‰æ•°
    api_key = st.secrets.get("OPENAI_API_KEY", os.environ.get("OPENAI_API_KEY", ""))
    if not api_key:
        return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚secrets ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.3,
        openai_api_key=api_key,
        max_retries=2,
    )

    chain = prompt | model | StrOutputParser()

    # å®Ÿè¡Œ
    try:
        result = chain.invoke({"question": user_text})
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

    return result

# ------------------------------
# Streamlit UI
# ------------------------------
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ§ ", layout="centered")
st.title(APP_TITLE)
st.caption("Python 3.11 / Streamlit + LangChain ãƒ‡ãƒ¢")

with st.expander("ã‚¢ãƒ—ãƒªã®æ¦‚è¦ãƒ»ä½¿ã„æ–¹", expanded=True):
    st.markdown(APP_DESC)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰é¸æŠ
st.sidebar.header("å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰")
expert_choice = st.sidebar.radio("å°‚é–€å®¶ã‚’é¸æŠ", ["A", "B"], index=0, horizontal=True)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("query_form", clear_on_submit=False):
    user_text = st.text_area(
        "è³ªå•ã‚„ä¾é ¼å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="ä¾‹ï¼šæ–°è¦D2Cã®ç«‹ã¡ä¸Šã’ã§ã€åˆæœˆã®é›†å®¢æˆ¦ç•¥ã‚’è€ƒãˆã¦ãã ã•ã„ï¼ˆAï¼‰ï¼\nç¤¾å†…FAQæ¤œç´¢ã®ç²¾åº¦ã‚’æ”¹å–„ã—ãŸã„ã€‚ã©ã®æŒ‡æ¨™ã‚’è¿½ãˆã°ã„ã„ï¼Ÿï¼ˆBï¼‰",
        height=160,
    )
    submitted = st.form_submit_button("é€ä¿¡")

# å®Ÿè¡Œã¨çµæœè¡¨ç¤º
if submitted:
    with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
        answer = ask_llm(user_text, expert_choice)
    st.markdown("### å›ç­”")
    st.write(answer)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("Â© 2024 Hiro_1. Built with Streamlit and LangChain.")
